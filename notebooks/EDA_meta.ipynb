{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Tablas Meta\n",
    "---\n",
    "tras nuestro analisis a las distintas tablas de datos, nos dimos cuenta de la similaridad en estructura de cada una de las tablas, por lo que crearemos un EDA modelo donde respetaremos los pasos para automatizar este proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #utilizaremos pandas para el mejor manejo de tablas\n",
    "import numpy as np #utilizaremos numpy para un mejor tratamiento de los datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # matplotlib y seaborn seran usados para graficar\n",
    "from pyspark.sql import SparkSession #pyspark lo usaremos como opcion al gran requerimiento de procesamiento de datos\n",
    "\n",
    "# Crea una sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MiAplicacionSpark\") \\\n",
    "    .getOrCreate()\n",
    "#importamos las funciones sql de pyspark para el manejo de columnas y valores\n",
    "from pyspark.sql.functions import col, sum, when, size, length, to_date, from_unixtime, year, regexp_replace, avg, lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Extraemos archivo.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74347"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json('../datasets/meta_Digital_Music.json', encoding='UTF-8')\n",
    "#observamos la cantidad de filas\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------------+--------+----+--------------------+-------+-------+---+--------------------+--------------------+--------------------+---------+--------------------+------------+-----+-----+--------------------+\n",
      "|            also_buy|           also_view|      asin|               brand|category|date|         description|details|feature|fit|            imageURL|     imageURLHighRes|            main_cat|    price|                rank|similar_item|tech1|tech2|               title|\n",
      "+--------------------+--------------------+----------+--------------------+--------+----+--------------------+-------+-------+---+--------------------+--------------------+--------------------+---------+--------------------+------------+-----+-----+--------------------+\n",
      "|[B000002UEN, B000...|[B000002UEN, B000...|0001377647| John Michael Talbot|      []|    |                  []|   null|     []|   |                  []|                  []|<img src=\"https:/...|   $18.99|58,291 in CDs & V...|            |     |     |Master Collection...|\n",
      "|[5558154950, B000...|[B000008KJ3, B000...|0001529145|Second Chapter of...|      []|    |                  []|   null|     []|   |                  []|                  []|<img src=\"https:/...|         |93,164 in CDs & V...|            |     |     |Hymns Collection:...|\n",
      "|[B00004RC05, B003...|[B003H8F4NA, B003...|0001527134|       Don Francisco|      []|    |                  []|   null|     []|   |                  []|                  []|<img src=\"https:/...|         |875,825 in CDs & ...|            |     |     |Early Works - Don...|\n",
      "|[B0000275QQ, 0001...|[B00000I7JO, B001...|0001388703|         Keith Green|      []|    |                  []|   null|     []|   |                  []|                  []|<img src=\"https:/...|   $13.01|203,263 in CDs & ...|            |     |     |So You Wanna Go B...|\n",
      "|[B0002N4JP2, 0760...|[B0002N4JP2, 0760...|0001526146|         Dallas Holm|      []|    |[1. Losing Game 2...|   null|     []|   |                  []|                  []|<img src=\"https:/...|         |399,269 in CDs & ...|            |     |     |Early Works - Dal...|\n",
      "|                  []|                  []|0005096421|   Michael Faircloth|      []|    |                  []|   null|     []|   |                  []|                  []|<img src=\"https:/...|         |779,669 in CDs & ...|            |     |     |The Glory of Love...|\n",
      "|                  []|[B0001XJ372, B000...|0006882919| John Michael Talbot|      []|    |                  []|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|    $5.95|444,064 in CDs &a...|            |     |     |Songs for Worship...|\n",
      "|[0830838015, B000...|[B00190TXSA, B000...|0006920055|        Michael Card|      []|    |                  []|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|   $34.98|36,667 in CDs &am...|            |     |     |The Life: The Com...|\n",
      "|[B000008LD5, B000...|[B000008LDH, B000...|0006935257| John Michael Talbot|      []|    |                  []|   null|     []|   |                  []|                  []|<img src=\"https:/...|         |147,412 in CDs & ...|            |     |     |The Lord's Supper...|\n",
      "|                  []|                  []|0159024684|Totally Catholic ...|      []|    |                 [.]|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|    $6.98|774,772 in CDs & ...|            |     |     |Sing &amp; Play S...|\n",
      "|                  []|[0382262948, 0382...|0382262921| Silver Burdett Ginn|      []|    |[The Music Connec...|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|   $18.79|694,369 in CDs & ...|            |     |     |The Music Connect...|\n",
      "|                  []|                  []|0439827469|              Edmark|      []|    |                  []|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|    $2.35|758,564 in CDs &a...|            |     |     |Mighty Math Numbe...|\n",
      "|                  []|                  []|0545069882|Transparent Language|      []|    |[Spanish Before Y...|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|$9,600.61|1,153,345 in CDs ...|            |     |     |Spanish Before Yo...|\n",
      "|                  []|[B00YZ82TPW, B000...|0545109620|                    |      []|    |[Just the CD. The...|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|    $6.14|242,922 in CDs &a...|            |     |     |Puff the Magic Dr...|\n",
      "|                  []|        [1481400568]|0545352886|      Bill Martin Jr|      []|    |[These entertaini...|   null|     []|   |                  []|                  []|<img src=\"https:/...|         |564,433 in CDs & ...|            |     |     |Chicka Chicka Boo...|\n",
      "|                  []|                  []|0578077698|         David Teems|      []|    |[The KING JAMES B...|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|  $500.00|506,806 in CDs &a...|            |     |     |         Speak To Me|\n",
      "|                  []|                  []|0615116809|      Ambika Wauters|      []|    |                  []|   null|     []|   |                  []|                  []|<img src=\"https:/...|         |1,079,906 in CDs ...|            |     |     |Angelic Prayers &...|\n",
      "|                  []|                  []|0615165982|Benita A. Esposit...|      []|    |[Soothing backgro...|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|         |980,759 in CDs &a...|            |     |     |<span class=\"a-si...|\n",
      "|                  []|                  []|0615516297|Dennis Buttimer A...|      []|    |[The guided medit...|   null|     []|   |                  []|                  []|<img src=\"https:/...|         |1,388,131 in CDs ...|            |     |     |<span class=\"a-si...|\n",
      "|[0692384251, B004...|        [0692384251]|0615897398|  Jacqueline Houston|      []|    |[The seasons are ...|   null|     []|   |[https://images-n...|[https://images-n...|<img src=\"https:/...|         |200,626 in CDs &a...|            |     |     |The Tales of Mind...|\n",
      "+--------------------+--------------------+----------+--------------------+--------+----+--------------------+-------+-------+---+--------------------+--------------------+--------------------+---------+--------------------+------------+-----+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Manejo de Duplicados.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas duplicadas: 8334\n",
      "Porcentaje de filas duplicadas: 0.11209598235302029\n"
     ]
    }
   ],
   "source": [
    "num_filas_duplicadas = df.count() - df.dropDuplicates().count()\n",
    "\n",
    "# Imprime el número de filas duplicadas\n",
    "print(\"Número de filas duplicadas:\", num_filas_duplicadas)\n",
    "print(f\"Porcentaje de filas duplicadas: {num_filas_duplicadas / df.count()}\")\n",
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos los duplicados ya que se repiten los valores en todas las columnas el mismo valor, con valores como also_buy que implican que es exactamente lo mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Manejo de Faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero revisemos los valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de filas: 66013\n",
      "+--------+---------+----+-----+--------+----+-----------+-------+-------+---+--------+---------------+--------+-----+----+------------+-----+-----+-----+\n",
      "|also_buy|also_view|asin|brand|category|date|description|details|feature|fit|imageURL|imageURLHighRes|main_cat|price|rank|similar_item|tech1|tech2|title|\n",
      "+--------+---------+----+-----+--------+----+-----------+-------+-------+---+--------+---------------+--------+-----+----+------------+-----+-----+-----+\n",
      "|       0|        0|   0|    0|       0|   0|          0|    534|      0|  0|       0|              0|       0|    0|   0|           0|    0|    0|    0|\n",
      "+--------+---------+----+-----+--------+----+-----------+-------+-------+---+--------+---------------+--------+-----+----+------------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcula la cantidad de nulos por columna\n",
    "conteo_de_nulos_por_columna = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "\n",
    "print(f\"cantidad de filas: {df.count()}\")\n",
    "# Muestra el resultado\n",
    "conteo_de_nulos_por_columna.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que la mayoria de las columnas no poseen faltantes, pero en un breve vistaso a nuestra tabla sabemos que esto no es cierto, por lo que convertiremos las filas vacias de todas las columnas de tipo array y todas las columnas de tipo string a nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_array_a_verificar = [\"also_buy\", \"also_view\", \"category\", \"description\", \"feature\"]\n",
    "\n",
    "# Verifica si las columnas string están vacías y las marca como nulas si es necesario\n",
    "for columna in columnas_array_a_verificar:\n",
    "    df = df.withColumn(columna, when(size(col(columna)) > 0, col(columna)).otherwise(None))\n",
    "\n",
    "columnas_string_a_verificar = [\"asin\", \"title\", \"price\", \"rank\", \"brand\", 'date', 'main_cat', 'similar_item', 'fit']\n",
    "\n",
    "# Verifica si las columnas string están vacías y las marca como nulas si es necesario\n",
    "for columna in columnas_string_a_verificar:\n",
    "    df = df.withColumn(columna, when((length(col(columna)) == 0) | (col(columna).isNull()), None).otherwise(col(columna)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66013\n",
      "+--------+---------+----+-----+--------+-----+-----------+-------+-------+-----+--------+---------------+--------+-----+----+------------+-----+-----+-----+\n",
      "|also_buy|also_view|asin|brand|category| date|description|details|feature|  fit|imageURL|imageURLHighRes|main_cat|price|rank|similar_item|tech1|tech2|title|\n",
      "+--------+---------+----+-----+--------+-----+-----------+-------+-------+-----+--------+---------------+--------+-----+----+------------+-----+-----+-----+\n",
      "|   57580|    53714|   0|13325|   66006|66008|      32979|    534|  65924|66013|       0|              0|       0|25902|   0|       66013|    0|    0|  513|\n",
      "+--------+---------+----+-----+--------+-----+-----------+-------+-------+-----+--------+---------------+--------+-----+----+------------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcula la cantidad de nulos por columna\n",
    "conteo_de_nulos_por_columna = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "\n",
    "print(df.count())\n",
    "# Muestra el resultado\n",
    "conteo_de_nulos_por_columna.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+----+----------------+-----------------+-----------------+-----------------+------------------+-----------------+-----+--------+---------------+--------+------------------+----+------------+-----+-----+------------------+\n",
      "|         also_buy|        also_view|asin|           brand|         category|             date|      description|           details|          feature|  fit|imageURL|imageURLHighRes|main_cat|             price|rank|similar_item|tech1|tech2|             title|\n",
      "+-----------------+-----------------+----+----------------+-----------------+-----------------+-----------------+------------------+-----------------+-----+--------+---------------+--------+------------------+----+------------+-----+-----+------------------+\n",
      "|87.22524351264144|81.36882129277566| 0.0|20.1854180237226|99.98939602805508|99.99242573432505|49.95834153878781|0.8089315740838926|99.86517807098602|100.0|     0.0|            0.0|     0.0|39.237725902473755| 0.0|       100.0|  0.0|  0.0|0.7771196582491326|\n",
      "+-----------------+-----------------+----+----------------+-----------------+-----------------+-----------------+------------------+-----------------+-----+--------+---------------+--------+------------------+----+------------+-----+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcula el total de filas en el DataFrame\n",
    "total_de_filas = df.count()\n",
    "\n",
    "# Calcula la cantidad de nulos por columna\n",
    "conteo_de_nulos_por_columna = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "\n",
    "# Calcula el porcentaje de nulos respecto al total de filas para cada columna\n",
    "porcentaje_de_nulos_por_columna = conteo_de_nulos_por_columna.select([((col(c) / total_de_filas) * 100).alias(c) for c in df.columns])\n",
    "\n",
    "# Muestra el resultado\n",
    "porcentaje_de_nulos_por_columna.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo nuestros reales valores faltantes tomamos la decision de hacer algo con esto, esto haremos con las siguiente columnas:\n",
    "- also_buy: conservamos la columna y convertiremos los faltantes en N/D ya que la poca informacion que tiene es relevante\n",
    "- also_view: similar a also_buy\n",
    "- asin: indica el id de cada metadata por lo que la conservamos\n",
    "- brand: conservamos y transformamos faltantes en N/D ya que es relevante\n",
    "- category: eliminamos la columna por un 99% de valores nulos\n",
    "- date: eliminamos por casi un 100% de valores faltantes\n",
    "- description: reemplazamos faltantes por N/D por su posible uso\n",
    "- details: trataremos esta columna mas adelante ya que extraeremos un dataframe de esta, pero eliminamos los valores nulos\n",
    "- feature: similar a category y date\n",
    "- fit: se elimina por 100% de valores faltantes\n",
    "- imageURL: no es relevante por lo que eliminamos\n",
    "- imageURLHighRes: similar a imageURL\n",
    "- main_cat: se conserva ya que indica la categoria.\n",
    "- price: se conserva y se trataran los faltantes tras un posterior analisis\n",
    "- rank: se conserva por su relevancia en el ranking \n",
    "- similar_item: similar a fit, se elimina\n",
    "- tech1 y tech2: si bien no figuran faltantes, tampoco son relevantes.\n",
    "- title: se eliminaran los valores nulos unicamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de nombres de columnas que deseas eliminar\n",
    "columnas_a_eliminar = [\"imageURL\", \"imageUrlHighRes\", \"tech1\", 'tech2', 'category', 'date', 'feature', 'fit', 'similar_item']\n",
    "\n",
    "# Elimina las columnas especificadas\n",
    "df = df.drop(*columnas_a_eliminar)\n",
    "\n",
    "\n",
    "# eliminamos los valores nulos\n",
    "df = df.na.drop(subset=['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- also_buy: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- also_view: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- description: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- details: struct (nullable = true)\n",
      " |    |-- \\n    Item Weight: \\n    : string (nullable = true)\n",
      " |    |-- \\n    Product Dimensions: \\n    : string (nullable = true)\n",
      " |    |-- ASIN:: string (nullable = true)\n",
      " |    |-- ASIN: : string (nullable = true)\n",
      " |    |-- Apparel: string (nullable = true)\n",
      " |    |-- Audio CD: string (nullable = true)\n",
      " |    |-- Audio Cassette: string (nullable = true)\n",
      " |    |-- Blu-ray Audio: string (nullable = true)\n",
      " |    |-- DVD: string (nullable = true)\n",
      " |    |-- DVD Audio: string (nullable = true)\n",
      " |    |-- Label:: string (nullable = true)\n",
      " |    |-- MP3 Music: string (nullable = true)\n",
      " |    |-- Note on Boxed Sets:: string (nullable = true)\n",
      " |    |-- Number of Discs:: string (nullable = true)\n",
      " |    |-- Original Release Date:: string (nullable = true)\n",
      " |    |-- Please Note:: string (nullable = true)\n",
      " |    |-- Run Time:: string (nullable = true)\n",
      " |    |-- SPARS Code:: string (nullable = true)\n",
      " |    |-- Shipping Weight:: string (nullable = true)\n",
      " |    |-- UPC:: string (nullable = true)\n",
      " |    |-- Vinyl: string (nullable = true)\n",
      " |    |-- Vinyl Bound: string (nullable = true)\n",
      " |-- main_cat: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- rank: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|    also_buy|   also_view|      asin|               brand|         description|             details|            main_cat|price|                rank|               title|\n",
      "+------------+------------+----------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|        null|        null|1415833044|Bill &amp; Gloria...|[Track Listings:\\...|                null|<img src=\"https:/...|$5.94|967,938 in CDs &a...|<span class=\"a-si...|\n",
      "|[1570199760]|[1932806105]|1570199329|Original Radio Br...|[With a style bui...|                null|<img src=\"https:/...| null|525,467 in CDs &a...|Suspense Classics...|\n",
      "|        null|        null|1611141028|                null|                null|                null|<img src=\"https:/...| null|2,786,515 in CDs ...|        Erian's Lair|\n",
      "|        null|        null|630221825X|        Havard Gimse|[Music on a Nordi...|                null|<img src=\"https:/...| null|1,979,984 in CDs ...|Music in a Nordic...|\n",
      "|        null|        null|B000003SDF|     Richard H. Kirk|                null|{null, null, B000...|<img src=\"https:/...| null|1,255,550 in CDs ...|Agents With False...|\n",
      "+------------+------------+----------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(*['category', 'date', 'similar_item', 'feature', 'fit'])\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- also_buy: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- also_view: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- description: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- details: struct (nullable = true)\n",
      " |    |-- \\n    Item Weight: \\n    : string (nullable = true)\n",
      " |    |-- \\n    Product Dimensions: \\n    : string (nullable = true)\n",
      " |    |-- ASIN:: string (nullable = true)\n",
      " |    |-- ASIN: : string (nullable = true)\n",
      " |    |-- Apparel: string (nullable = true)\n",
      " |    |-- Audio CD: string (nullable = true)\n",
      " |    |-- Audio Cassette: string (nullable = true)\n",
      " |    |-- Blu-ray Audio: string (nullable = true)\n",
      " |    |-- DVD: string (nullable = true)\n",
      " |    |-- DVD Audio: string (nullable = true)\n",
      " |    |-- Label:: string (nullable = true)\n",
      " |    |-- MP3 Music: string (nullable = true)\n",
      " |    |-- Note on Boxed Sets:: string (nullable = true)\n",
      " |    |-- Number of Discs:: string (nullable = true)\n",
      " |    |-- Original Release Date:: string (nullable = true)\n",
      " |    |-- Please Note:: string (nullable = true)\n",
      " |    |-- Run Time:: string (nullable = true)\n",
      " |    |-- SPARS Code:: string (nullable = true)\n",
      " |    |-- Shipping Weight:: string (nullable = true)\n",
      " |    |-- UPC:: string (nullable = true)\n",
      " |    |-- Vinyl: string (nullable = true)\n",
      " |    |-- Vinyl Bound: string (nullable = true)\n",
      " |-- main_cat: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- rank: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| price|\n",
      "+------+\n",
      "| 59.87|\n",
      "|143.98|\n",
      "| 52.58|\n",
      "| 100.0|\n",
      "| 86.46|\n",
      "|  65.0|\n",
      "| 53.22|\n",
      "| 85.36|\n",
      "|135.12|\n",
      "| 54.79|\n",
      "| 99.95|\n",
      "| 54.94|\n",
      "|149.98|\n",
      "| 58.95|\n",
      "| 78.95|\n",
      "|  95.0|\n",
      "|  80.0|\n",
      "| 70.09|\n",
      "| 99.92|\n",
      "|154.38|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"price\", regexp_replace(col(\"price\"), \"\\\\$\", \"\").cast(\"float\"))\n",
    "\n",
    "# Paso 1: Calcular el promedio de los valores no nulos en la columna 'price'\n",
    "promedio_price = df.select(avg(col(\"price\"))).first()[0]\n",
    "\n",
    "# Calcular el rango intercuartil (IQR) de la columna 'price'\n",
    "q1 = df.approxQuantile(\"price\", [0.25], 0.01)[0]\n",
    "q3 = df.approxQuantile(\"price\", [0.75], 0.01)[0]\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Definir un umbral para identificar outliers (por ejemplo, 1.5 veces el IQR)\n",
    "umbral_superior = q3 + 1.5 * iqr\n",
    "umbral_inferior = q1 - 1.5 * iqr\n",
    "\n",
    "# Identificar los outliers en la columna 'price'\n",
    "outliers = df.filter((col(\"price\") > umbral_superior) | (col(\"price\") < umbral_inferior))\n",
    "\n",
    "# Mostrar los outliers\n",
    "outliers.select(\"price\").show()\n",
    "\n",
    "# Paso 2: Rellenar los valores nulos en la columna 'price' con el promedio\n",
    "#df = df.fillna(promedio_price, subset=[\"price\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('main_cat', lit('Digital Music'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza regexp_replace para eliminar todos los caracteres que no sean números\n",
    "df = df.withColumn('rank', regexp_replace(df['rank'], '[^0-9]', ''))\n",
    "\n",
    "# Convierte la columna 'rank' a tipo Integer\n",
    "df = df.withColumn('rank', df['rank'].cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<span class=\"a-size-medium a-color-secondary a-text-normal\"'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fila = df.collect()[0]\n",
    "fila['title']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sistema_amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
